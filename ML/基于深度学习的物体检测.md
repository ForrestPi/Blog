## 基于深度学习的物体检测



首先简单介绍一下传统物体检测的方法和基于深度学习的物体检测方法。

传统方法使用滑动窗口的框架，把一张图分解成几百万个不同位置不同尺度的子窗口，针对每一个窗口使用分类器判断是否包含目标物体。传统方法针对不同的类别的物体，一般会设计不同的特征和分类算法，比如人脸检测的经典算法是Harr特征+Adaboosting分类器；行人检测的经典算法是HOG(histogram of gradients) + Support Vector Machine；一般性物体的检测的话是HOG的特征加上DPM(deformable part model)的算法。

> 基于深度学习的物体检测的经典算法是RCNN系列： RCNN，fast RCNN (Ross Girshick)，faster RCNN (少卿、凯明、孙剑、Ross)。这三个工作的核心思想是分别是：使用更好的CNN模型判断候选区域的类别；复用预计算的sharing feature map加快模型训练和物体检测的速度；进一步使用sharing feature map大幅提高计算候选区域的速度。其实基于深度学习的物体检测也可以看成对海量滑动窗口分类，只是用全卷积的方式。

RCNN系列算法还是将物体检测分为两个步骤。现在还有一些工作是端到端(end-to-end)的物体检测，比如说YOLO(You Only Look Once: Unified, Real-Time Object Detection)和SSD(SSD: Single Shot MultiBox Detector)这样的算法。这两个算法号称和faster RCNN精度相似但速度更快。物体检测正负样本极端非均衡，two-stage cascade可以更好的应对非均衡。端到端学习是否可以超越faster RCNN还需要更多研究实验。

深度学习可以做到传统方法无法企及的精度，这是关键中的关键，如果说这个优点是1的话，其它的优点都是1后面的0。深度学习革命爆发在2011~2012年，11年的时候在语音识别领域有重大突破，12年的时候在图像识别领域有重大突破。深度学习革命，使得计算机视觉在很多应用领域达到了实用水平，催生了工业界的大量应用。这也是为什么在11年前，机器视觉&人工智能的博士生都是找不到工作的，但是12年之后，尤其是现在，都变成了被众多公司高薪争夺的宝贝。

另外深度学习成为标配，还有其它的优点。

> 第一，深度学习算法的通用性很强，刚才提到的检测，在传统算法里面，针对不同的物体需要定制化不同的算法。相比来看，基于深度学习的算法更加通用，比如faster RCNN在人脸、行人、一般物体检测任务上都可以取得非常好的效果。
>
> 
>
> 第二，深度学习获得的特征(feature)有很强的迁移能力。所谓特征迁移能力，指的是在A任务上学习到一些特征，在B任务上使用也可以获得非常好的效果。例如在ImageNet（物体为主）上学习到的特征在场景分类任务上也能取得非常好的效果。
>
> 
>
> 第三， 工程开发、优化、维护成本低。深度学习计算主要是卷积和矩阵乘，针对这种计算优化，所有深度学习算法都可以提升性能。另外，通过组合现有的层(layer)，我们可以实现大量复杂网络结构和一些算法，开发维护的成本低。想想同时开发、维护Boosting，Random Forest等算法是非常痛苦的一件事情。



简单来说，机器学习就是学习输入到输出的一个映射，传统方法使用浅层的简单映射，现在深度学习是多层的复合映射。深度学习有很多的自由度，学习目标和学习方法有很多种选择，网络结构层与层之间有无数的可能连接方式，每一层映射的具体形式到底是卷积，还是全连接，还是其它的形式，并没有限制，其实除了全连接和卷积之外，还可以用其它的映射形式，比如说去年ICCV上的一个工作：微软研究院用Random Forest做为新的映射形式。

深度学习的技术框架是一棵树形结构。

训练平台是树根，如caffe、tensorflow等。现在深度学习还处于实验科学阶段，实验效率很大程度上决定着研发效率，好的训练平台可以把实验周期从一个月缩短到一天，对于深度学习研发非常重要。

模型是树干。自06年提出深度学习概念，学术界花了六年时间才认识到模型结构的研究才是深度学习的重点。典型的成果有AlexNet、VGGNet、GoogleNet、ResNet等。学术界大家主要研究怎么把模型做的精度更好。在工业界我们还要考虑怎么把模型做得更快，更小。

在树干上有几个主干的枝丫，对应着计算机视觉里的核心任务，包括了检测、识别、分割、特征点定位、序列学习等五个大的任务，任何计算机视觉的具体的应用都可以由这五个任务组合而成。以人脸识别为例，人脸识别要完成整个流程，要涉及到人脸的检测、特征点定位，特征的提取&验证。这就包含了检测、特征点定位和识别三个部分。

我们在刚才提到的那五个重要的主干方向其实都投入了非常大的研究力量，一方面是保证我们在学术界的前沿有所突破，另一方面，针对我们一些重要应用也开发出了一整套与学术界并行的方法，能够做到十倍的加速和百倍模型的压缩，同时保持很好的精度。这个问题中提到的四篇论文主要是我们在这五个计算机视觉的核心任务上取得的一些研究方向的成果。其实我们除了在研究方向成果之外在工业实用方面有更大、更多的成果，比如我们的人脸检测在做到学术界最好结果的同时能做到300FPS的速度。人脸特征点的定位超过学术界最好结果的同时，做到3000FPS的速度。在学术界公开的论文中，我还没有看到这样的性能。

在深度学习领域有一个简单但又非常通用的原理。在学习时，指导信息越丰富、越精细，学习的效果一般来说也会越好。
举个简单的例子，在数据量充足的情况下，如果我对我图像类别的标注仅仅是动物、植物、场景的话，学习出来的模型和特征可能一般。但是如果把这些类别标记细化，比如最开始有十类数据，我们把它细化到一千类，例如把狗分成斑点狗、斗牛犬等，把猫分成波斯猫、大花猫等，通常来说可以学习到更好的模型和更加好的特征。
另一个例子是物体检测，如果在bounding box的基础上增加额外的监督信息通长会得到更好的结果。比如标注出人脸的眼睛、鼻子、嘴的位置，人脸的角度，种族性别男女等属性，做成一个多任务学习的算法的话，通常来说能得到更好的效果。

两个代表性工作可以参考：Joint cascade face detection and alignment，Facial landmark detection by deep multi-task learning。
有时候多个标注/任务是并列关系，可以通过Multi-Task Learning的框架来学习。另外一些情况，多个任务是递进关系，前一个任务的结果可以帮助后一个任务，例如将每一个人都独立的检测出来之后再分割每个人身体的Mask。合理利用这种递进关系，可以得到比并列关系更好的结果，这其实就是Instance segmentation的核心思想。因为同传统语义分割不同的是，传统语义分割只需要对物体类别进行分类，不需要区分不同的个体。物体分割(Instance segmentation)是既需要区分类别，又需要区分同一物体的个体，所以深度学习的网络需要学习到比之前语义分割任务更多的信息。这方面微软亚洲研究院的戴继峰做了非常开创性的工作。我们商汤科技石建萍高级研究员的工作也非常有创建性。通过多尺度局部区域融合的方法，端到端的实现了instance segmentation 物体类别与区分统一类别不同个体的信息。