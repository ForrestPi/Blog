# 深度学习框架自动求导

推荐一个更好用的自动求导工具。[autograd](https://link.zhihu.com/?target=https%3A//github.com/HIPS/autograd)

Just run pip install autograd

缺陷是，你需要特别注意，这个自动求导的功能指的是对函数第一个参数求导。 所以，所有需要求导的都得以第一个参数传进去

比如这个[A Step by Step Backpropagation Example](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)， 可以写成

```python
import autograd.numpy as np
from autograd import grad

def sigmoid(x):
    return 1.0/(np.exp(-x) + 1)

def predict(params,input):
    (W1,B1),(W2,B2) = params
    hidden = sigmoid(np.dot(W1,input) + B1)
    output = sigmoid(np.dot(W2,hidden) + B2)
    return output

def loss(params,input,target):
    return (0.5*(target-predict(params,input))**2).sum()

loss_grad = grad(loss)

def train(params, input, target):
    grad = loss_grad(params,input,target)
    return [(W-0.5*dW,B-0.5*dB) for ((dW,dB),(W,B)) in zip(grad,params)]

W1 = np.array(
    [ [0.15,0.20],
      [0.25,0.30]])

B1 = 0.35

W2 = np.array(
    [ [0.40,0.45],
      [0.50,0.55]])

B2 = 0.60

PARAMS = [(W1,B1),(W2,B2)]
INPUT = np.array([0.05,0.10])
TARGET = np.array([0.01,0.99])

while True:
    PARAMS = train(PARAMS,INPUT,TARGET)
```

这可比一堆数学公式容易理解多了。

